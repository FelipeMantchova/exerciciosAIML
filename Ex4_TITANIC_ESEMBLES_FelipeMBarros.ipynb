{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "WHV0_Xw3Hl6m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BJfZ3-FmG_nC"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "titanic_data = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar as features (X) e o alvo (y)\n",
        "X = titanic_data.drop('Survived', axis=1)\n",
        "y = titanic_data['Survived']\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "sVgbEMizHmo8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir colunas categóricas e numéricas\n",
        "categorical_cols = [cname for cname in X.columns if\n",
        "                    X[cname].nunique() < 10 and\n",
        "                    X[cname].dtype == \"object\"]\n",
        "numeric_cols = [cname for cname in X.columns if\n",
        "                X[cname].dtype in ['int64', 'float64']]"
      ],
      "metadata": {
        "id": "kuzZONHTkdxP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Criar um ColumnTransformer para aplicar transformers específicos a colunas específicas\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Visualizar as primeiras linhas do conjunto de treinamento após o pré-processamento\n",
        "X_train_preprocessed = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
        "print(X_train_preprocessed.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p7eGDqFkGvQ",
        "outputId": "b2f83705-f423-4dbf-bf0b-df7cf856fde8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0         1         2         3         4         5    6    7    8   \\\n",
            "0 -0.453066 -1.614136  1.232263 -0.470722 -0.479342 -0.078684  0.0  1.0  0.0   \n",
            "1  1.113874 -0.400551 -0.500482 -0.470722 -0.479342 -0.377145  0.0  1.0  0.0   \n",
            "2 -0.254275  0.813034  0.192616 -0.470722 -0.479342 -0.474867  0.0  1.0  0.0   \n",
            "3  1.000836  0.813034 -0.269449  0.379923 -0.479342 -0.476230  0.0  1.0  0.0   \n",
            "4  1.425702  0.813034 -1.809667  2.931860  2.048742 -0.025249  1.0  0.0  0.0   \n",
            "\n",
            "    9    10  \n",
            "0  0.0  1.0  \n",
            "1  0.0  1.0  \n",
            "2  0.0  1.0  \n",
            "3  0.0  1.0  \n",
            "4  0.0  1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Definir os modelos individuais\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
        "logistic_regression_model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Criar um VotingClassifier\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('rf', random_forest_model),\n",
        "    ('gb', gradient_boosting_model),\n",
        "    ('lr', logistic_regression_model)\n",
        "], voting='soft')  # 'soft' utiliza as probabilidades para a votação\n",
        "\n",
        "# Criar um StackingClassifier\n",
        "stacking_classifier = StackingClassifier(estimators=[\n",
        "    ('rf', random_forest_model),\n",
        "    ('gb', gradient_boosting_model),\n",
        "    ('lr', logistic_regression_model)\n",
        "], final_estimator=LogisticRegression())\n",
        "\n",
        "# Criar um pipeline para o ensemble\n",
        "ensemble_voting_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', voting_classifier)  # Pode ser substituído por 'stacking_classifier'\n",
        "])\n",
        "\n",
        "ensemble_stacking_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', stacking_classifier)  # Pode ser substituído por 'stacking_classifier'\n",
        "])\n",
        "\n",
        "# Avaliar o ensemble usando validação cruzada\n",
        "cv_scores_voting = cross_val_score(ensemble_voting_pipeline, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "cv_scores_stacking = cross_val_score(ensemble_stacking_pipeline, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Exibir a média das pontuações\n",
        "print(\"Accuracy média do Ensemble (voting):\", cv_scores_voting.mean())\n",
        "print(\"Accuracy média do Ensemble (stacking):\", cv_scores_stacking.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKVmiWnlkpsn",
        "outputId": "dfa10c35-711e-47fc-85e2-0cde99e9ee8f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy média do Ensemble (voting): 0.7879919653505743\n",
            "Accuracy média do Ensemble (stacking): 0.7958131944008537\n"
          ]
        }
      ]
    }
  ]
}